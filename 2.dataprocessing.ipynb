{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9687af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "import networkx as nx\n",
    "from netAPI import adjacency_matrix\n",
    "\n",
    "from GNNAPI import buildVNNConfig\n",
    "# from GNNAPI import EarlyStopper\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "#from NetRepLearnerV2 import NetGNNAttRepr\n",
    "from NetRepLearner_mh import NetReprLearning\n",
    "# from NetRepLearner_mh import GMLearning\n",
    "import pandas as pd\n",
    "from netAPI import pickleLoad, pickleDump\n",
    "# from GNNAPI import nnSquare, nnExp\n",
    "from GNNAPI import VNN_MLP\n",
    "from GNNAPI import GNN_VNN_Layer\n",
    "from GNNAPI import buildLaplacian\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist,pdist\n",
    "import scipy.stats\n",
    "# from GNNAPI import DirectTensor\n",
    "import scipy.optimize\n",
    "import scipy.stats as stats\n",
    "\n",
    "from netAPI import loadNetworkMat\n",
    "from netAPI import adjacency_matrix\n",
    "from GNNAPI import GNN_VNN_Layer\n",
    "from GNNAPI import VNNDefaultConfig\n",
    "from GNNAPI import buildLaplacian\n",
    "from GNNAPI import buildVNNConfig\n",
    "# from GNNAPI import matrixNormalize\n",
    "# from GNNAPI import GNN_VNN_Multiclass_Layer\n",
    "from GNNAPI import NNmodel\n",
    "from GNNAPI import dmerge\n",
    "import time\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from esda.moran import Moran\n",
    "from esda.geary import Geary\n",
    "import libpysal\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from visdom import Visdom\n",
    "import warnings\n",
    "from csv import writer\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.mixture import GaussianMixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc16725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inbetween(o,d,A,win,wout):\n",
    "    distance = A[o,d]\n",
    "    \n",
    "    if win[A[o,:]<distance].shape[0]>0: \n",
    "        # number of available jobs in a shorter distance\n",
    "        ofts = win[A[o,:]<distance].sum(axis=0,keepdims=True)[0]\n",
    "    else:\n",
    "        ofts = 0\n",
    "    if wout[A[d,:]<distance].shape[0]>0: \n",
    "        # number of available residences in a shorter distance\n",
    "        dfts = wout[A[d,:]<distance].sum(axis=0,keepdims=True)[0]\n",
    "    else:\n",
    "        dfts = 0\n",
    "#     print(ofts,dfts,win[d],wout[o])\n",
    "    ofts = ofts/(win[d]+1)\n",
    "    dfts = dfts/(wout[o]+1)\n",
    "    between_fts = torch.FloatTensor([ofts,dfts,distance]).view(1,3)\n",
    "#     print(between_fts)\n",
    "    return between_fts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitByNodes = True\n",
    "externalities = True\n",
    "# if modelmode='g', conventional singly constrained gravity model, other parameters will be ignored\n",
    "modelmode = 'p'\n",
    "# gravi con, modelmode = 'p', attention = True, directEmebdding = False\n",
    "# GCN + MLP, modelmode = 'p', attention = False, VNNattraction = Truepath = 'LEHD/'\n",
    "\n",
    "cities = [\n",
    "    ('New York City', 'ny', ['New York County, NY', 'Queens County, NY','Kings County, NY','Bronx County, NY','Richmond County, NY']),\n",
    "    ('Los Angeles', 'ca', ['Los Angeles County, CA']),\n",
    "    ('Chicago', 'il', ['Cook County, IL']),\n",
    "    ('Houston', 'tx', ['Harris County, TX']),\n",
    "    ('Boston', 'ma', ['Suffolk County, MA', 'Middlesex County, MA']),\n",
    "    ('Phoenix', 'az', ['Maricopa County, AZ']),\n",
    "    ('Philadelphia', 'pa', ['Philadelphia County, PA']),\n",
    "    ('San Antonio', 'tx', ['Bexar County, TX']),\n",
    "    ('San Diego', 'ca', ['San Diego County, CA']),\n",
    "    ('Dallas', 'tx', ['Dallas County, TX']),\n",
    "    ('San Jose', 'ca', ['Santa Clara County, CA']),\n",
    "    ('Austin', 'tx', ['Travis County, TX']),\n",
    "]\n",
    "\n",
    "splitByNodes = True\n",
    "externalities = True\n",
    "# if modelmode='g', conventional singly constrained gravity model, other parameters will be ignored\n",
    "modelmode = 'p'\n",
    "# gravi con, modelmode = 'p', attention = True, directEmebdding = False\n",
    "# GCN + MLP, modelmode = 'p', attention = False, VNNattraction = True\n",
    "attention = True\n",
    "VNNattraction = False\n",
    "directEmebdding = False #learn node embedding directly (MLP) or through GNNs\n",
    "\n",
    "for city,state, counties in cities:\n",
    "\n",
    "   \n",
    "    print('processing LEHD')\n",
    "    LEHD = pd.read_csv(f'LEHD/{city}_flow.csv')\n",
    "    nodes = list(set(LEHD.O.unique().tolist()+LEHD.D.unique().tolist()))\n",
    "    G = nx.DiGraph()    ('Boston', 'ma', ['Suffolk County, MA', 'Middlesex County, MA']),\n",
    "    ('Phoenix', 'az', ['Maricopa County, AZ']),\n",
    "    ('Philadelphia', 'pa', ['Philadelphia County, PA']),\n",
    "    ('San Antonio', 'tx', ['Bexar County, TX']),\n",
    "    ('San Diego', 'ca', ['San Diego County, CA']),\n",
    "    ('Dallas', 'tx', ['Dallas County, TX']),\n",
    "    ('San Jose', 'ca', ['Santa Clara County, CA']),\n",
    "    ('Austin', 'tx', ['Travis County, TX']),\n",
    "    G.add_weighted_edges_from([(LEHD.iloc[e]['O'], LEHD.iloc[e]['D'],\n",
    "                            LEHD.iloc[e]['Volume']) for e in range(len(LEHD))])\n",
    "    #main parameters\n",
    "    mainepochs = 100000\n",
    "    ed = 16 #node embedding dimensionality\n",
    "    splitSeed = 0\n",
    "    seed = 0\n",
    "\n",
    "\n",
    "    #define the adjacency matrix\n",
    "    OD = 1.0 * np.array(nx.adjacency_matrix(G,sorted(list(G.nodes()))).todense())\n",
    "    wind = (OD.sum(axis = 0) > 0) & (OD.sum(axis = 1) > 0)\n",
    "    location = read_location_from_ct(state,nodes)\n",
    "    A = scipy.spatial.distance_matrix(location,location)\n",
    "    n = A.shape[0]\n",
    "\n",
    "    train,valid, test = getTrainTestbyNodes(A,train_p= 0.7,  seed = splitSeed)\n",
    "    node_train = train\n",
    "    node_valid = valid\n",
    "    node_test = test\n",
    "    train = np.full(A.shape,True)*train*(train.reshape(-1,1))\n",
    "    valid = np.full(A.shape,True)*valid*(valid.reshape(-1,1))\n",
    "    test = np.invert(train+valid)\n",
    "\n",
    "    if externalities:\n",
    "        print('processing POI')\n",
    "        nodefts = pd.read_csv('LEHD/'+city+'fts.csv')\n",
    "        nodefts = nodefts.set_index('GEOID').loc[sorted(list(G.nodes()))].values\n",
    "    else:\n",
    "        nodefts = torch.FloatTensor(np.eye(n))\n",
    "\n",
    "    nodefts = torch.FloatTensor(nodefts)\n",
    "    nodefts_train = nodefts[node_train]\n",
    "    #some basic stats\n",
    "    print('City {}, Network of size {}, non-zero edges = {}, unique edge values = {}, avg. edge = {},total network weight = {}'.format(city, len(G), len(G.edges()), len(np.unique(A)), A.mean(), A.sum()))\n",
    "\n",
    "    A_train = A[:,node_train][node_train]\n",
    "    nodefts_train = nodefts[node_train]\n",
    "    OD_train = OD[:,node_train][node_train]\n",
    "#     location_train = location[node_train]\n",
    "    edges_train = A_train.nonzero()\n",
    "    wout_train = OD_train.sum(axis = 1)\n",
    "    win_train = OD_train.sum(axis = 0)\n",
    "    for i,o in enumerate(edges_train[0]):\n",
    "        d = edges_train[1][i]\n",
    "        if o!=d:\n",
    "            if i == 0:\n",
    "                between_fts_train = inbetween(o,d,A_train,win_train,wout_train)\n",
    "            else:\n",
    "                fts_temp = inbetween(o,d,A_train,win_train,wout_train)\n",
    "                between_fts_train = torch.concat([between_fts_train,fts_temp],axis=0)\n",
    "            if i%100 == 0 and i >100:\n",
    "                progress_bar(i,len(edges_train[0]))\n",
    "\n",
    "    A_valid = A[:,node_valid][node_valid]\n",
    "    nodefts_valid = nodefts[node_valid]\n",
    "    OD_valid = OD[:,node_valid][node_valid]\n",
    "    wout_valid = OD_valid.sum(axis = 1)\n",
    "    win_valid = OD_valid.sum(axis = 0)\n",
    "    edges_valid = A_valid.nonzero()\n",
    "    for i,o in enumerate(edges_valid[0]):\n",
    "        d = edges_valid[1][i]\n",
    "        if o!=d:\n",
    "            if i == 0:\n",
    "                between_fts_valid = inbetween(o,d,A_valid,win_valid,wout_valid)\n",
    "            else:\n",
    "                fts_temp = inbetween(o,d,A_valid,win_valid,wout_valid)\n",
    "                between_fts_valid = torch.concat([between_fts_valid,fts_temp],axis=0)\n",
    "            if i%100 == 0 and i >100:\n",
    "                progress_bar(i,len(edges_valid[0]))\n",
    "    torch.save(nodefts_train, 'training/'+city+'_nodefts_train.pt')\n",
    "    torch.save(nodefts_valid, 'training/'+city+'_nodefts_valid.pt')\n",
    "\n",
    "    torch.save(between_fts_train, 'training/'+city+'_between_fts_train.pt')\n",
    "    torch.save(between_fts_valid, 'training/'+city+'_between_fts_valid.pt')\n",
    "    \n",
    "    A_train = torch.FloatTensor(A_train)\n",
    "    A_valid = torch.FloatTensor(A_valid)\n",
    "    \n",
    "    torch.save(A_train, 'training/'+city+'_A_train.pt')\n",
    "    torch.save(A_valid, 'training/'+city+'_A_valid.pt')\n",
    "    \n",
    "    torch.save(OD_train, 'training/'+city+'_OD_train.pt')\n",
    "    torch.save(OD_valid, 'training/'+city+'_OD_valid.pt')\n",
    "    \n",
    "\n",
    "    A_test = A[:,node_test][node_test]\n",
    "\n",
    "    nodefts_test = nodefts[node_test]\n",
    "\n",
    "    OD_test = OD[:,node_test][node_test]\n",
    "    OD_test = torch.FloatTensor(OD_test)\n",
    "    win_test = OD_test.sum(axis = 0)\n",
    "    wout_test = OD_test.sum(axis = 1)\n",
    "\n",
    "    edges_test = A_test.nonzero()\n",
    "    for i,o in enumerate(edges_test[0]):\n",
    "        d = edges_test[1][i]\n",
    "        if o!=d:\n",
    "            if i == 0:\n",
    "                between_fts_test = inbetween(o,d,A_test,win_test,wout_test)\n",
    "            else:\n",
    "                fts_temp = inbetween(o,d,A_test,win_test,wout_test)\n",
    "                between_fts_test = torch.concat([between_fts_test,fts_temp],axis=0)\n",
    "            if i%100 == 0 and i >100:\n",
    "                progress_bar(i,len(edges_test[0]))\n",
    "\n",
    "    A_test = torch.FloatTensor(A_test).to(torch.device(\"cuda\"))\n",
    "\n",
    "    torch.save(A_test, 'training/'+city+'_A_test.pt')\n",
    "    torch.save(OD_test, 'training/'+city+'_OD_test.pt')\n",
    "    torch.save(nodefts_test, 'traini8ng/'+city+'_nodefts_test.pt')\n",
    "    torch.save(between_fts_test, 'training/'+city+'_between_fts_test.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
