{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9687af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "import networkx as nx\n",
    "from netAPI import adjacency_matrix\n",
    "\n",
    "from GNNAPI import buildVNNConfig\n",
    "# from GNNAPI import EarlyStopper\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "#from NetRepLearnerV2 import NetGNNAttRepr\n",
    "from NetRepLearner_mh import NetReprLearning\n",
    "# from NetRepLearner_mh import GMLearning\n",
    "import pandas as pd\n",
    "from netAPI import pickleLoad, pickleDump\n",
    "# from GNNAPI import nnSquare, nnExp\n",
    "from GNNAPI import VNN_MLP\n",
    "from GNNAPI import GNN_VNN_Layer\n",
    "from GNNAPI import buildLaplacian\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist,pdist\n",
    "import scipy.stats\n",
    "# from GNNAPI import DirectTensor\n",
    "import scipy.optimize\n",
    "import scipy.stats as stats\n",
    "\n",
    "from netAPI import loadNetworkMat\n",
    "from netAPI import adjacency_matrix\n",
    "from GNNAPI import GNN_VNN_Layer\n",
    "from GNNAPI import VNNDefaultConfig\n",
    "from GNNAPI import buildLaplacian\n",
    "from GNNAPI import buildVNNConfig\n",
    "# from GNNAPI import matrixNormalize\n",
    "# from GNNAPI import GNN_VNN_Multiclass_Layer\n",
    "from GNNAPI import NNmodel\n",
    "from GNNAPI import dmerge\n",
    "import time\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from esda.moran import Moran\n",
    "from esda.geary import Geary\n",
    "import libpysal\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from visdom import Visdom\n",
    "import warnings\n",
    "from csv import writer\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.mixture import GaussianMixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc16725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inbetween(o,d,A,win,wout):\n",
    "    distance = A[o,d]\n",
    "    \n",
    "    if win[A[o,:]<distance].shape[0]>0: \n",
    "        # number of available jobs in a shorter distance\n",
    "        ofts = win[A[o,:]<distance].sum(axis=0,keepdims=True)[0]\n",
    "    else:\n",
    "        ofts = 0\n",
    "    if wout[A[d,:]<distance].shape[0]>0: \n",
    "        # number of available residences in a shorter distance\n",
    "        dfts = wout[A[d,:]<distance].sum(axis=0,keepdims=True)[0]\n",
    "    else:\n",
    "        dfts = 0\n",
    "#     print(ofts,dfts,win[d],wout[o])\n",
    "    ofts = ofts/(win[d]+1)\n",
    "    dfts = dfts/(wout[o]+1)\n",
    "    between_fts = torch.FloatTensor([ofts,dfts,distance]).view(1,3)\n",
    "#     print(between_fts)\n",
    "    return between_fts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb84c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing LEHD\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m city,state, counties \u001b[38;5;129;01min\u001b[39;00m cities:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessing LEHD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m     LEHD \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLEHD/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_flow.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(LEHD\u001b[38;5;241m.\u001b[39mO\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;241m+\u001b[39mLEHD\u001b[38;5;241m.\u001b[39mD\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m     39\u001b[0m     G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mDiGraph()    (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBoston\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mma\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuffolk County, MA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiddlesex County, MA\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "splitByNodes = True\n",
    "externalities = True\n",
    "# if modelmode='g', conventional singly constrained gravity model, other parameters will be ignored\n",
    "modelmode = 'p'\n",
    "# gravi con, modelmode = 'p', attention = True, directEmebdding = False\n",
    "# GCN + MLP, modelmode = 'p', attention = False, VNNattraction = Truepath = 'LEHD/'\n",
    "\n",
    "cities = [\n",
    "    ('New York City', 'ny', ['New York County, NY', 'Queens County, NY','Kings County, NY','Bronx County, NY','Richmond County, NY']),\n",
    "    ('Los Angeles', 'ca', ['Los Angeles County, CA']),\n",
    "    ('Chicago', 'il', ['Cook County, IL']),\n",
    "    ('Houston', 'tx', ['Harris County, TX']),\n",
    "    ('Boston', 'ma', ['Suffolk County, MA', 'Middlesex County, MA']),\n",
    "    ('Phoenix', 'az', ['Maricopa County, AZ']),\n",
    "    ('Philadelphia', 'pa', ['Philadelphia County, PA']),\n",
    "    ('San Antonio', 'tx', ['Bexar County, TX']),\n",
    "    ('San Diego', 'ca', ['San Diego County, CA']),\n",
    "    ('Dallas', 'tx', ['Dallas County, TX']),\n",
    "    ('San Jose', 'ca', ['Santa Clara County, CA']),\n",
    "    ('Austin', 'tx', ['Travis County, TX']),\n",
    "]\n",
    "\n",
    "splitByNodes = True\n",
    "externalities = True\n",
    "# if modelmode='g', conventional singly constrained gravity model, other parameters will be ignored\n",
    "modelmode = 'p'\n",
    "# gravi con, modelmode = 'p', attention = True, directEmebdding = False\n",
    "# GCN + MLP, modelmode = 'p', attention = False, VNNattraction = True\n",
    "attention = True\n",
    "VNNattraction = False\n",
    "directEmebdding = False #learn node embedding directly (MLP) or through GNNs\n",
    "\n",
    "for city,state, counties in cities:\n",
    "\n",
    "   \n",
    "    print('processing LEHD')\n",
    "    LEHD = pd.read_csv(f'LEHD/{city}_flow.csv')\n",
    "    nodes = list(set(LEHD.O.unique().tolist()+LEHD.D.unique().tolist()))\n",
    "    G = nx.DiGraph()    ('Boston', 'ma', ['Suffolk County, MA', 'Middlesex County, MA']),\n",
    "    ('Phoenix', 'az', ['Maricopa County, AZ']),\n",
    "    ('Philadelphia', 'pa', ['Philadelphia County, PA']),\n",
    "    ('San Antonio', 'tx', ['Bexar County, TX']),\n",
    "    ('San Diego', 'ca', ['San Diego County, CA']),\n",
    "    ('Dallas', 'tx', ['Dallas County, TX']),\n",
    "    ('San Jose', 'ca', ['Santa Clara County, CA']),\n",
    "    ('Austin', 'tx', ['Travis County, TX']),\n",
    "    G.add_weighted_edges_from([(LEHD.iloc[e]['O'], LEHD.iloc[e]['D'],\n",
    "                            LEHD.iloc[e]['Volume']) for e in range(len(LEHD))])\n",
    "    #main parameters\n",
    "    mainepochs = 100000\n",
    "    ed = 16 #node embedding dimensionality\n",
    "    splitSeed = 0\n",
    "    seed = 0\n",
    "\n",
    "\n",
    "    #define the adjacency matrix\n",
    "    OD = 1.0 * np.array(nx.adjacency_matrix(G,sorted(list(G.nodes()))).todense())\n",
    "    wind = (OD.sum(axis = 0) > 0) & (OD.sum(axis = 1) > 0)\n",
    "    location = read_location_from_ct(state,nodes)\n",
    "    A = scipy.spatial.distance_matrix(location,location)\n",
    "    n = A.shape[0]\n",
    "\n",
    "    train,valid, test = getTrainTestbyNodes(A,train_p= 0.7,  seed = splitSeed)\n",
    "    node_train = train\n",
    "    node_valid = valid\n",
    "    node_test = test\n",
    "    train = np.full(A.shape,True)*train*(train.reshape(-1,1))\n",
    "    valid = np.full(A.shape,True)*valid*(valid.reshape(-1,1))\n",
    "    test = np.invert(train+valid)\n",
    "\n",
    "    if externalities:\n",
    "        print('processing POI')\n",
    "        nodefts = pd.read_csv('LEHD/'+city+'fts.csv')\n",
    "        nodefts = nodefts.set_index('GEOID').loc[sorted(list(G.nodes()))].values\n",
    "    else:\n",
    "        nodefts = torch.FloatTensor(np.eye(n))\n",
    "\n",
    "    nodefts = torch.FloatTensor(nodefts)\n",
    "    nodefts_train = nodefts[node_train]\n",
    "    #some basic stats\n",
    "    print('City {}, Network of size {}, non-zero edges = {}, unique edge values = {}, avg. edge = {},total network weight = {}'.format(city, len(G), len(G.edges()), len(np.unique(A)), A.mean(), A.sum()))\n",
    "\n",
    "    A_train = A[:,node_train][node_train]\n",
    "    nodefts_train = nodefts[node_train]\n",
    "    OD_train = OD[:,node_train][node_train]\n",
    "#     location_train = location[node_train]\n",
    "    edges_train = A_train.nonzero()\n",
    "    wout_train = OD_train.sum(axis = 1)\n",
    "    win_train = OD_train.sum(axis = 0)\n",
    "    for i,o in enumerate(edges_train[0]):\n",
    "        d = edges_train[1][i]\n",
    "        if o!=d:\n",
    "            if i == 0:\n",
    "                between_fts_train = inbetween(o,d,A_train,win_train,wout_train)\n",
    "            else:\n",
    "                fts_temp = inbetween(o,d,A_train,win_train,wout_train)\n",
    "                between_fts_train = torch.concat([between_fts_train,fts_temp],axis=0)\n",
    "            if i%100 == 0 and i >100:\n",
    "                progress_bar(i,len(edges_train[0]))\n",
    "\n",
    "    A_valid = A[:,node_valid][node_valid]\n",
    "    nodefts_valid = nodefts[node_valid]\n",
    "    OD_valid = OD[:,node_valid][node_valid]\n",
    "    wout_valid = OD_valid.sum(axis = 1)\n",
    "    win_valid = OD_valid.sum(axis = 0)\n",
    "    edges_valid = A_valid.nonzero()\n",
    "    for i,o in enumerate(edges_valid[0]):\n",
    "        d = edges_valid[1][i]\n",
    "        if o!=d:\n",
    "            if i == 0:\n",
    "                between_fts_valid = inbetween(o,d,A_valid,win_valid,wout_valid)\n",
    "            else:\n",
    "                fts_temp = inbetween(o,d,A_valid,win_valid,wout_valid)\n",
    "                between_fts_valid = torch.concat([between_fts_valid,fts_temp],axis=0)\n",
    "            if i%100 == 0 and i >100:\n",
    "                progress_bar(i,len(edges_valid[0]))\n",
    "    torch.save(nodefts_train, 'training/'+city+'_nodefts_train.pt')\n",
    "    torch.save(nodefts_valid, 'training/'+city+'_nodefts_valid.pt')\n",
    "\n",
    "    torch.save(between_fts_train, 'training/'+city+'_between_fts_train.pt')\n",
    "    torch.save(between_fts_valid, 'training/'+city+'_between_fts_valid.pt')\n",
    "    \n",
    "    A_train = torch.FloatTensor(A_train)\n",
    "    A_valid = torch.FloatTensor(A_valid)\n",
    "    \n",
    "    torch.save(A_train, 'training/'+city+'_A_train.pt')\n",
    "    torch.save(A_valid, 'training/'+city+'_A_valid.pt')\n",
    "    \n",
    "    torch.save(OD_train, 'training/'+city+'_OD_train.pt')\n",
    "    torch.save(OD_valid, 'training/'+city+'_OD_valid.pt')\n",
    "    \n",
    "\n",
    "    A_test = A[:,node_test][node_test]\n",
    "\n",
    "    nodefts_test = nodefts[node_test]\n",
    "\n",
    "    OD_test = OD[:,node_test][node_test]\n",
    "    OD_test = torch.FloatTensor(OD_test)\n",
    "    win_test = OD_test.sum(axis = 0)\n",
    "    wout_test = OD_test.sum(axis = 1)\n",
    "\n",
    "    edges_test = A_test.nonzero()\n",
    "    for i,o in enumerate(edges_test[0]):\n",
    "        d = edges_test[1][i]\n",
    "        if o!=d:\n",
    "            if i == 0:\n",
    "                between_fts_test = inbetween(o,d,A_test,win_test,wout_test)\n",
    "            else:\n",
    "                fts_temp = inbetween(o,d,A_test,win_test,wout_test)\n",
    "                between_fts_test = torch.concat([between_fts_test,fts_temp],axis=0)\n",
    "            if i%100 == 0 and i >100:\n",
    "                progress_bar(i,len(edges_test[0]))\n",
    "\n",
    "    A_test = torch.FloatTensor(A_test).to(torch.device(\"cuda\"))\n",
    "\n",
    "    torch.save(A_test, 'training/'+city+'_A_test.pt')\n",
    "    torch.save(OD_test, 'training/'+city+'_OD_test.pt')\n",
    "    torch.save(nodefts_test, 'traini8ng/'+city+'_nodefts_test.pt')\n",
    "    torch.save(between_fts_test, 'training/'+city+'_between_fts_test.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad083d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing LEHD\n",
      "processing POI\n",
      "City New York City, Network of size 2318, non-zero edges = 1042346, unique edge values = 2685404, avg. edge = 0.15006745730547927,total network weight = 806331.056467046\n",
      "processing LEHD\n",
      "processing POI\n",
      "City Los Angeles, Network of size 2495, non-zero edges = 1241479, unique edge values = 3111266, avg. edge = 0.3185754685307331,total network weight = 1983140.2559905269\n",
      "processing LEHD\n",
      "processing POI\n",
      "City Chicago, Network of size 1331, non-zero edges = 447912, unique edge values = 885116, avg. edge = 0.2346814080956095,total network weight = 415752.43000726606\n",
      "processing LEHD\n",
      "processing POI\n",
      "City Houston, Network of size 1115, non-zero edges = 428305, unique edge values = 621056, avg. edge = 0.2728102902280133,total network weight = 339164.5730687218\n",
      "processing LEHD\n",
      "processing POI\n",
      "City Boston, Network of size 591, non-zero edges = 150740, unique edge values = 174346, avg. edge = 0.21133376364390902,total network weight = 73814.86829930819\n",
      "processing LEHD\n",
      "processing POI\n",
      "City Phoenix, Network of size 1009, non-zero edges = 382368, unique edge values = 508537, avg. edge = 0.3296852183524734,total network weight = 335646.25678550446\n",
      "processing LEHD\n",
      "processing POI\n",
      "City Philadelphia, Network of size 406, non-zero edges = 73535, unique edge values = 82216, avg. edge = 0.1024110898192458,total network weight = 16881.034401445202\n",
      "processing LEHD\n",
      "processing POI\n",
      "City San Antonio, Network of size 375, non-zero edges = 86288, unique edge values = 70126, avg. edge = 0.18016597675406681,total network weight = 25335.840481040646\n",
      "processing LEHD\n",
      "processing POI\n",
      "City San Diego, Network of size 736, non-zero edges = 222321, unique edge values = 270481, avg. edge = 0.2908695030238691,total network weight = 157562.8463100178\n",
      "processing LEHD\n",
      "processing POI\n",
      "City Dallas, Network of size 645, non-zero edges = 163074, unique edge values = 207691, avg. edge = 0.20681292720241645,total network weight = 86039.34803938531\n",
      "processing LEHD\n",
      "processing POI\n",
      "City San Jose, Network of size 408, non-zero edges = 93087, unique edge values = 83029, avg. edge = 0.17763859148895944,total network weight = 29570.430493618143\n",
      "processing LEHD\n",
      "processing POI\n",
      "City Austin, Network of size 290, non-zero edges = 51869, unique edge values = 41906, avg. edge = 0.17574710043749536,total network weight = 14780.33114679336\n"
     ]
    }
   ],
   "source": [
    "\n",
    "splitByNodes = True\n",
    "externalities = True\n",
    "# if modelmode='g', conventional singly constrained gravity model, other parameters will be ignored\n",
    "modelmode = 'p'\n",
    "# gravi con, modelmode = 'p', attention = True, directEmebdding = False\n",
    "# GCN + MLP, modelmode = 'p', attention = False, VNNattraction = Truepath = 'LEHD/'\n",
    "\n",
    "cities = [\n",
    "    ('New York City', 'ny', ['New York County, NY', 'Queens County, NY','Kings County, NY','Bronx County, NY','Richmond County, NY']),\n",
    "    ('Los Angeles', 'ca', ['Los Angeles County, CA']),\n",
    "    ('Chicago', 'il', ['Cook County, IL']),\n",
    "    ('Houston', 'tx', ['Harris County, TX']),\n",
    "    ('Boston', 'ma', ['Suffolk County, MA', 'Middlesex County, MA']),\n",
    "    ('Phoenix', 'az', ['Maricopa County, AZ']),\n",
    "    ('Philadelphia', 'pa', ['Philadelphia County, PA']),\n",
    "    ('San Antonio', 'tx', ['Bexar County, TX']),\n",
    "    ('San Diego', 'ca', ['San Diego County, CA']),\n",
    "    ('Dallas', 'tx', ['Dallas County, TX']),\n",
    "    ('San Jose', 'ca', ['Santa Clara County, CA']),\n",
    "    ('Austin', 'tx', ['Travis County, TX']),\n",
    "]\n",
    "\n",
    "splitByNodes = True\n",
    "externalities = True\n",
    "# if modelmode='g', conventional singly constrained gravity model, other parameters will be ignored\n",
    "modelmode = 'p'\n",
    "# gravi con, modelmode = 'p', attention = True, directEmebdding = False\n",
    "# GCN + MLP, modelmode = 'p', attention = False, VNNattraction = True\n",
    "attention = True\n",
    "VNNattraction = False\n",
    "directEmebdding = False #learn node embedding directly (MLP) or through GNNs\n",
    "\n",
    "for city,state, counties in cities:\n",
    "\n",
    "   \n",
    "    print('processing LEHD')\n",
    "    LEHD = pd.read_csv(f'LEHD/{city}_flow.csv')\n",
    "    nodes = list(set(LEHD.O.unique().tolist()+LEHD.D.unique().tolist()))\n",
    "    G = nx.DiGraph()    \n",
    "    G.add_weighted_edges_from([(LEHD.iloc[e]['O'], LEHD.iloc[e]['D'],\n",
    "                            LEHD.iloc[e]['Volume']) for e in range(len(LEHD))])\n",
    "    #main parameters\n",
    "    mainepochs = 100000\n",
    "    ed = 16 #node embedding dimensionality\n",
    "    splitSeed = 0\n",
    "    seed = 0\n",
    "\n",
    "\n",
    "    #define the adjacency matrix\n",
    "    OD = 1.0 * np.array(nx.adjacency_matrix(G,sorted(list(G.nodes()))).todense())\n",
    "    wind = (OD.sum(axis = 0) > 0) & (OD.sum(axis = 1) > 0)\n",
    "    area = read_area_from_ct(state,nodes)\n",
    "    location = read_location_from_ct(state,nodes)\n",
    "    A = scipy.spatial.distance_matrix(location,location)\n",
    "    n = A.shape[0]\n",
    "\n",
    "    train,valid, test = getTrainTestbyNodes(A,train_p= 0.7,  seed = splitSeed)\n",
    "    node_train = train\n",
    "    node_valid = valid\n",
    "    node_test = test\n",
    "    train = np.full(A.shape,True)*train*(train.reshape(-1,1))\n",
    "    valid = np.full(A.shape,True)*valid*(valid.reshape(-1,1))\n",
    "    test = np.invert(train+valid)\n",
    "\n",
    "    if externalities:\n",
    "        print('processing POI')\n",
    "        nodefts = pd.read_csv('LEHD/'+city+'fts.csv')\n",
    "        nodefts = nodefts.set_index('GEOID').loc[sorted(list(G.nodes()))].values\n",
    "    else:\n",
    "        nodefts = torch.FloatTensor(np.eye(n))\n",
    "\n",
    "    nodefts = torch.FloatTensor(nodefts)\n",
    "    nodefts_train = nodefts[node_train]\n",
    "    #some basic stats\n",
    "    print('City {}, Network of size {}, non-zero edges = {}, unique edge values = {}, avg. edge = {},total network weight = {}'.format(city, len(G), len(G.edges()), len(np.unique(A)), A.mean(), A.sum()))\n",
    "\n",
    "    area_train = area[node_train]\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(area_train, 'training/'+city+'_area_train.pt')\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
